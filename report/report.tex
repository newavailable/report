\documentclass{article}
\usepackage{indentfirst}

\begin{document}
\setlength{\parindent}{2em}
\bibliographystyle{unsrt}


\begin{abstract}
    Medical image segmentation
\end{abstract}

\section{Introduction}

p1 introduces three parts:the usage of segmentation in medical image field,segmentation,
including 2D 3D and the application of image of segmentation, and the business value

p2 introduces some problem traditional image segmentation method

p3 introduce the our target, including we would like to use different module, what is our dataset, the rusult and comparing these result, and some other attentions.

p4 introduce what module we choose

p5 introduce the challenge we meet

p6 introduces the strucuter of this article



\section{Literature Review}
ResUnet is a new architecture that combines the advantages of deep residual learning and Unet.\cite{zhang2018road}
This structure simplifies training and optimizes extraction. In the medical industry, ResUNet can measure spinal parameters\cite{weng2019artificial} and extract the path of cell segmentation\cite{lessmann2019iterative},satellite imagery of medical organisms.
According to the research results\cite{weng2019artificial}, the results obtained using the ResUNet structure are not much different from the doctor's diagnosis results and have high accuracy.
In addition, RestUNet can also be used in clinical medicine to automatically segment zebrafish blood vessels (very similar to humans). It solves the problem that it is difficult to identify the segmented overlapping area due to uneven fluorescence distribution.\cite{zhang2019zebrafish}

For semantic segmentation of high-resolution aerial images, a new deep learning architecture ResUNet-a can be used.
This is based on the encoder/decoder paradigm, where the standard convolution is replaced with a ResNet unit, which contains multiple parallel atrous convolutions.
After some experiments prove that this method can improve semantic segmentation performance.\cite{diakogiannis2020resunet}

In medical image segmentation, a structure called ResUNet++ is also used.
It is a semantic segmentation neural network using residual blocks, extrusion and excitation blocks, spatial pyramid pool (ASPP), and attention blocks.
It is mainly used for the segmentation of intestinal polyps and is suitable for a relatively small number of images.\cite{jha2019resunet++}

Stacked U-nets are stacked based on U-nets and combine the image characteristics of different resolutions while maintaining the resolution.
S-Unets solves the traditional model structure that limits images' effectiveness in secondary tasks such as pixel-level positioning or classification.\cite{shah2018stacked}
After a series of processing, the S-Unets structure can remove the mesh artifacts that often plague the expanded network structure's output.\cite{ghosh2018stacked}
S-Unets structure combined with multiple outputs, reducing thresholds, searching for the shortest path, and other optimization techniques can improve accuracy and are usually used to extract road satellite images.\cite{sun2018stacked}

U2-Net is a deep learning framework for photoreceptor layer segmentation in pathological OCT scanning.
This structure, combined with cognitive uncertainty graphs, highlighting potential areas of pathology or segmentation errors, can speed up manual labeling.\cite{orlando2019u2}

Generative Adversarial Network (GAN) is an effective data anonymization method and provides an additional form of data augmentation.
GAN can extract and generate labeled synthetic retinal images in the medical field and can synthesize brain CT through brain nuclear magnetic images.\cite{shin2018medical}
At the same time, GAN can be used to segment lungs in chest X images.
GAN is composed of generating G network and discriminating D network.
The generator is used to generate data from random noise.
The discriminator can distinguish the real data and the data generated by the generator.\cite{munawar2020segmentation}

DeepLab v3 is a convolution-based image segmentation technology, which can be used to diagnose melanoma cases.
This technique uses convolution, where the filter is applied to each image interval's pixel matrix rather than to all adjacent pixels.
In this way, the generated feature map can maintain spatial resolution without consuming a lot of calculation time.
DeepLab uses multiple convolutions, followed by a pyramid pooling method, where four parallel atrous convolutions are applied to the input, and all have different atrous rates.\cite{wang2018skin}
\section{Background}

\subsection{Unet}
\subsection{Unet++}
\subsection{SegNet}
\subsection{Seg-Unet}
\subsection{Res-Unet}

\section{Experiment and Results}
In this section, the nuclei data set used for the experiments, the evaluation measures and lastly the results are discussed in detail.
\subsection{Data Set}
The data set consists of 735 nuclei images.
The images were acquired under various conditions and vary in the cell type, magnification, and imaging modality.
Each nuclei image is annotated with a series of masks marked by experts, and each image is represented by an associate ImageID.
Files belonging to an image are contained in a folder with the ImageID, and within each folder, there are two subfolders:

1.“images” that contains the image file

2. “masks” that contains the segmented masks of each nucleus.
This kind of folder is only included in the training set.
Each mask contains one nucleus, and masks are not allowed to overlap which means there should be no pixel belongs to two masks.

In the pre-processing step, both training and testing data were down-sampled to keep the images light and manageable.
The testing data's original sizes were recorded to up-sample the predicted masks and create correct run-length encodings later on.
The pre-processing step is explained in a visual format on the simple example in Figure X. Among the data, 670 are used as training data, and 65 are chosen as testing data to measure the networks' performance.

\subsection{Evaluation Measures}

\subsection{Hyperparameter Setup}
\subsection{Results}

\section{Conclusion}


\bibliography{bibfile}
\end{document}