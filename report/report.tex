\documentclass{article}
\usepackage{indentfirst}

\begin{document}
\setlength{\parindent}{2em}
\bibliographystyle{unsrt}


\begin{abstract}
    Medical image segmentation
\end{abstract}

\section{Introduction}

Medical image is an essential auxiliary means in modern medical therapy.
For example, magnetic resonance imaging (MRI), computed tomography (CT), and digital mammography are widely used to diagnose diseases and map objects in anatomy.\cite{pham2000current}
The collected image can be either 2-dimensional (such as microscope images) or 3-dimensional (CT images).
There is no obvious difference between these two types of image processing for human beings, while for machines, the 2D image operation is much simpler.

With the development of deep learning, image processing technology also makes much progress.
Although image processing has been studied in the past using various traditional computer vision and machine learning techniques, the deep learning revolution is a historic step in this field because the image segmentation method, which is tackled using deep architectures, is surpassing other approaches by a large margin in terms of accuracy and sometimes even efficiency.\cite{DBLP:journals/corr/Garcia-GarciaOO17}

The application of image segmentation also includes medical image segmentation.
Because of the high accuracy and efficiency, this deep learning method replaces extracting hand-crafted features of machine learning approaches and has become increasingly prevalent.\cite{hesamian2019deep}

Considering the importance of medical images to diagnose patients' situation, few doctors can conclude without these images.
It is obvious there are no high-quality medical resources in underdeveloped areas, and many diseases cannot be diagnosed quickly and receive adequate medical treatment, resulting in high mortality.
While with the help of medical image segmentation even an inexperienced doctor can draw accurate conclusions to patients' situations, which may save more lives.

However, challenges with Training Deep Models can not be ignored.
Overfitting and gradient vanishing are two inevitable problems.
The solutions to these problems are closely related to the specific model.
At the same time, training time and memory should also be taken into consideration.

Therefore, this project intends to know the performance of different model which has been used in the medical image field and compares some typical models such as Unet, Unet++, SegNet, Seg-Unet and ResUnet.

The paper is structured as follows.
Section 2 describes related work in the area of image segmentation, especially medical image segmentation.
In Section 3, the five models which have been compared are described.
Section 4 describes the dataset, the experiments and discusses the results.
The conclusion and future work are provided in Section 5.


\section{Literature Review}
ResUnet is a new architecture that combines the advantages of deep residual learning and Unet.\cite{zhang2018road}
This structure simplifies training and optimizes extraction. In the medical industry, ResUNet can measure spinal parameters\cite{weng2019artificial} and extract the path of cell segmentation\cite{lessmann2019iterative},satellite imagery of medical organisms.
According to the research results\cite{weng2019artificial}, the results obtained using the ResUNet structure are not much different from the doctor's diagnosis results and have high accuracy.
In addition, RestUNet can also be used in clinical medicine to automatically segment zebrafish blood vessels (very similar to humans). It solves the problem that it is difficult to identify the segmented overlapping area due to uneven fluorescence distribution.\cite{zhang2019zebrafish}

For semantic segmentation of high-resolution aerial images, a new deep learning architecture ResUNet-a can be used.
This is based on the encoder/decoder paradigm, where the standard convolution is replaced with a ResNet unit, which contains multiple parallel atrous convolutions.
After some experiments prove that this method can improve semantic segmentation performance.\cite{diakogiannis2020resunet}

In medical image segmentation, a structure called ResUNet++ is also used.
It is a semantic segmentation neural network using residual blocks, extrusion and excitation blocks, spatial pyramid pool (ASPP), and attention blocks.
It is mainly used for the segmentation of intestinal polyps and is suitable for a relatively small number of images.\cite{jha2019resunet++}

Stacked U-nets are stacked based on U-nets and combine the image characteristics of different resolutions while maintaining the resolution.
S-Unets solves the traditional model structure that limits images' effectiveness in secondary tasks such as pixel-level positioning or classification.\cite{shah2018stacked}
After a series of processing, the S-Unets structure can remove the mesh artifacts that often plague the expanded network structure's output.\cite{ghosh2018stacked}
S-Unets structure combined with multiple outputs, reducing thresholds, searching for the shortest path, and other optimization techniques can improve accuracy and are usually used to extract road satellite images.\cite{sun2018stacked}

U2-Net is a deep learning framework for photoreceptor layer segmentation in pathological OCT scanning.
This structure, combined with cognitive uncertainty graphs, highlighting potential areas of pathology or segmentation errors, can speed up manual labeling.\cite{orlando2019u2}

Generative Adversarial Network (GAN) is an effective data anonymization method and provides an additional form of data augmentation.
GAN can extract and generate labeled synthetic retinal images in the medical field and can synthesize brain CT through brain nuclear magnetic images.\cite{shin2018medical}
At the same time, GAN can be used to segment lungs in chest X images.
GAN is composed of generating G network and discriminating D network.
The generator is used to generate data from random noise.
The discriminator can distinguish the real data and the data generated by the generator.\cite{munawar2020segmentation}

DeepLab v3 is a convolution-based image segmentation technology, which can be used to diagnose melanoma cases.
This technique uses convolution, where the filter is applied to each image interval's pixel matrix rather than to all adjacent pixels.
In this way, the generated feature map can maintain spatial resolution without consuming a lot of calculation time.
DeepLab uses multiple convolutions, followed by a pyramid pooling method, where four parallel atrous convolutions are applied to the input, and all have different atrous rates.\cite{wang2018skin}
\section{Background}

\subsection{Unet}
\subsection{Unet++}
\subsection{SegNet}
\subsection{Seg-Unet}
\subsection{Res-Unet}

\section{Experiment and Results}
In this section, the nuclei data set used for the experiments, the evaluation measures and lastly the results are discussed in detail.
\subsection{Data Set}
The data set consists of 735 nuclei images.
The images were acquired under various conditions and vary in the cell type, magnification, and imaging modality.
Each nuclei image is annotated with a series of masks marked by experts, and each image is represented by an associate ImageID.
Files belonging to an image are contained in a folder with the ImageID, and within each folder, there are two subfolders:

1.“images” that contains the image file

2. “masks” that contains the segmented masks of each nucleus.
This kind of folder is only included in the training set.
Each mask contains one nucleus, and masks are not allowed to overlap which means there should be no pixel belongs to two masks.

In the pre-processing step, both training and testing data were down-sampled to keep the images light and manageable.
The testing data's original sizes were recorded to up-sample the predicted masks and create correct run-length encodings later on.
The pre-processing step is explained in a visual format on the simple example in Figure X. Among the data, 670 are used as training data, and 65 are chosen as testing data to measure the networks' performance.

\subsection{Evaluation Measures}

\subsection{Hyperparameter Setup}
\subsection{Results}

\section{Conclusion}


\bibliography{bibfile}
\end{document}